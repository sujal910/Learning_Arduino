{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNExa4SAENfK6SefYSUHOTo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujal910/Learning_Arduino/blob/main/01_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Introdution** to tensor"
      ],
      "metadata": {
        "id": "dNFVTeePeCkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is a Tensor?**\n",
        "\n",
        "In PyTorch, a **Tensor** is the fundamental building block for data. Think of it as a generic container for numbers, similar to a NumPy array, but with two special superpowers:\n",
        "1.  **GPU Support:** Tensors can run on video cards (GPUs) for massive speedups.\n",
        "2.  **Automatic Differentiation:** Tensors can track the math operations performed on them to help calculate gradients for AI learning.\n",
        "\n",
        "#### **The Hierarchy of Dimensions**\n",
        "The word \"Tensor\" is the general name for arrays of any dimension:\n",
        "\n",
        "* **0-D Tensor (Scalar):** A single number (e.g., `7`). Has magnitude but no direction.\n",
        "* **1-D Tensor (Vector):** A list of numbers (e.g., `[7, 7]`). Has magnitude and direction.\n",
        "* **2-D Tensor (Matrix):** A grid of numbers (rows & columns). commonly used for spreadsheets or black-and-white images.\n",
        "* **3-D+ Tensor:** A cube or hyper-cube of numbers. Used for things like RGB images (Height x Width x Color) or video batches.\n",
        "\n",
        "> **Note:** In Deep Learning, we use the word \"Tensor\" to refer to all of the above, regardless of how many dimensions they have."
      ],
      "metadata": {
        "id": "Ovw3bUQuuNT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting With Tensors"
      ],
      "metadata": {
        "id": "JSNQRKJIfSUK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5igSvcRdX8N",
        "outputId": "08cc4919-d0be-4027-9633-3bd5e7a78d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APGYJTynq2QP",
        "outputId": "f4607c56-f4f4-43c4-a9cf-0fe18e183281"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 25 05:38:10 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0             27W /   70W |     104MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chech for GPU acces with Pytorch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVF5s92_rkwX",
        "outputId": "67990fc2-2234-4106-bb57-59bb24c20303"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to tensor\n",
        "\n",
        "### creating a tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K3gvoojEfIja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "import torch\n",
        "scalar = torch.tensor(9)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLMBzYeQgzZP",
        "outputId": "051def9a-9b50-4a84-8875-8f308de7f663"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In data science libraries like NumPy and PyTorch, .ndim is an attribute that tells you the number of dimensions (or axes) a data object has.\n",
        "\n"
      ],
      "metadata": {
        "id": "97IPjfsju89p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icXEFqwmjmFA",
        "outputId": "67c50cbb-d6e5-4165-f48e-6e320c6972aa"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting tensor back as python int\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrxEKgmLi-GZ",
        "outputId": "53accd60-8a75-461c-ca27-d2df40519910"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([9,8])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWtf70IjsbX",
        "outputId": "47e0a8d3-25e1-4d9a-8e03-4ab7c29ec18c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeNx4NNHlEXX",
        "outputId": "017418e0-59b3-4f18-cb20-b27b96423819"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NORpIFhzlI9-",
        "outputId": "d60b5865-9cea-4dea-e623-a26362e49eeb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Matrix"
      ],
      "metadata": {
        "id": "SyxF4Vwwlpxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A 2x3 Matrix (2 rows, 3 columns)\n",
        "data = [[1, 2, 3],\n",
        "        [4, 5, 6]]\n",
        "\n",
        "MATRIX = torch.tensor(data)\n",
        "\n",
        "MATRIX\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8rvna_lNOH",
        "outputId": "bedfbac8-1dd1-46d7-ed68-f76537d92026"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0zWnzKKl75n",
        "outputId": "820e9640-9242-4437-ea11-ce300da6f2c0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkjDIhWKmgW5",
        "outputId": "69cba4cd-a862-4f96-d6f5-9f052062bbdb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBz5lZlFmAgB",
        "outputId": "1d591291-4d76-4278-b47c-815eba458bd3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whOwzoD_msAL",
        "outputId": "e416cbe5-c04c-4645-d88d-dd2e33acf3f6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor"
      ],
      "metadata": {
        "id": "f4UUT9xqmxFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.tensor([[[[1,2,3],\n",
        "                        [7,8,9],\n",
        "                        [8,9,5]]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km_cw0RJp38c",
        "outputId": "005f91f6-dd91-4e5a-f9be-3c943543055d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1, 2, 3],\n",
              "          [7, 8, 9],\n",
              "          [8, 9, 5]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding this Tensor\n",
        "\n",
        "**1. Why is `.ndim` 4?**\n",
        "You can determine dimensions by counting the opening brackets `[` before the first number appears:\n",
        "* `[` (1st dim)\n",
        "* `[` (2nd dim)\n",
        "* `[` (3rd dim)\n",
        "* `[` (4th dim)\n",
        "* `1` (The data starts here)\n",
        "\n",
        "**2. Why is `.shape` [1, 1, 3, 3]?**\n",
        "This specific shape corresponds to a common image format in Deep Learning:\n",
        "* **Batch Size: 1** (1 image in this group)\n",
        "* **Channels: 1** (1 color channel, e.g., Grayscale)\n",
        "* **Height: 3** (3 pixels high)\n",
        "* **Width: 3** (3 pixels wide)"
      ],
      "metadata": {
        "id": "VTdbwtjqtJhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4a0BIzGqmgx",
        "outputId": "2e6b2f16-501d-4117-88bc-83e014693e49"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlAKy8PCq80g",
        "outputId": "b0c6e2b6-46e8-435e-bc5e-8a7686577542"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QKrZ0x_q_6p",
        "outputId": "0bb5cced-057a-4c0f-d5d1-0279c776ce50"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [7, 8, 9],\n",
              "         [8, 9, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors\n",
        "In machine learning and data science, random tensors are essentially multi-dimensional arrays filled with random numbers. While it might seem counterintuitive to start with \"random\" values, they are the vital \"seed\" that allows computers to learn.\n",
        "\n",
        "The primary reason we use random tensors is to break symmetry and provide a starting point for optimization.\n",
        "\n",
        "1. Breaking Symmetry: If all neurons start with the same value (like 0), they will all learn the exact same thing. Randomness ensures every neuron starts unique so they can \"specialize\" in different patterns.\n",
        "\n",
        "2. A Starting Point: To use Gradient Descent (the way AI learns), the model needs a place to start on the \"map.\" A random tensor places the model at a random spot so it can begin trekking toward the best solution.\n",
        "\n",
        "3. Preventing Stagnation: Randomness helps the model avoid getting \"stuck\" in a poor solution early on, giving it a better chance to find the most accurate result."
      ],
      "metadata": {
        "id": "3XgmHnnUrFiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cereating a random tensors\n",
        "import torch\n",
        "random_tensor = torch.rand(2 ,3 , 3)\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "4sGqEW7brJNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b774683-0d72-413f-e5ae-7358c6a72b03"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2566, 0.7936, 0.9408],\n",
              "         [0.1332, 0.9346, 0.5936],\n",
              "         [0.8694, 0.5677, 0.7411]],\n",
              "\n",
              "        [[0.4294, 0.8854, 0.5739],\n",
              "         [0.2666, 0.6274, 0.2696],\n",
              "         [0.4414, 0.2969, 0.8317]]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp8KCZ6cWpMp",
        "outputId": "120e7856-a2f9-438d-d1f8-a8d14ac735f1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a zero tensor\n",
        "import torch\n",
        "zero_tensor = torch.zeros(3,4)\n",
        "zero_tensor"
      ],
      "metadata": {
        "id": "EB8sDJd7XJez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff03c56d-31c2-4fee-8fa6-c8a9c4740bf1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "random_tensor = torch.rand(3, 4)\n",
        "zero_tensor = torch.zeros(3, 4)\n",
        "# Now perform the element-wise multiplication\n",
        "zero_tensor * random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgEKHMft_McA",
        "outputId": "062e2145-e43f-4e37-ae94-0537fdcaa33c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearting all ones (Identity)\n",
        "ones_tensor = torch.ones(3,4)\n",
        "ones_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I79hLaFjAEky",
        "outputId": "cdbc3e28-9625-4b99-9647-f62cfb711ea6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_tensor.dtype\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg-fWE1WAW3y",
        "outputId": "2a176bcc-3b1c-4cb8-8693-f91184d4f81b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_tensor * random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cod5uR2AjDy",
        "outputId": "5d205439-9361-4129-9ed5-11549e443b72"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
              "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
              "        [0.8860, 0.5832, 0.3376, 0.8090]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh4hoRT__9zb",
        "outputId": "8b4bddb3-589f-4ad4-ba0b-b77eddded089"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a range of Tensors and Tensor-like"
      ],
      "metadata": {
        "id": "CqRIEIF9_abE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten = torch.arange(1 , 11)\n",
        "one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqwZ2PFRBML7",
        "outputId": "162f86ef-060d-42f7-ff0f-f34b6ae57aec"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Difference between `torch.arange()` and `torch.range()`\n",
        "\n",
        "**`torch.arange(start, end, step)`**\n",
        "Generates values starting from `start` (inclusive) up to `end` (exclusive), using a given step size.\n",
        "It behaves like Python’s built-in `range()` but works for tensors and supports floating-point steps.\n",
        "This is the recommended and standard way to generate ranges in PyTorch.\n",
        "\n",
        "**`torch.range(start, end, step)`**\n",
        "Generates values from `start` to `end`, including both endpoints.\n",
        "This function is deprecated, may be removed in future versions, and can cause floating-point precision issues.\n",
        "It should not be used in new code.\n",
        "\n",
        "---\n",
        "\n",
        "### Comparison Table\n",
        "\n",
        "| Feature             | torch.arange() | torch.range() |\n",
        "| ------------------- | -------------- | ------------- |\n",
        "| End included        | No             | Yes           |\n",
        "| Deprecated          | No             | Yes           |\n",
        "| Floating-point safe | Yes            | Risky         |\n",
        "| Recommended         | Yes            | No            |\n",
        "\n",
        "---\n",
        "\n",
        "### Recommendation\n",
        "\n",
        "Always use `torch.arange()` and avoid `torch.range()`.\n"
      ],
      "metadata": {
        "id": "TUTo5IXQB2m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Tensors like\n",
        "ten_Zeros = torch.zeros_like(input=one_to_ten)\n",
        "ten_Zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLBAA-3eBU3n",
        "outputId": "308ceeef-79fd-40b5-e4cf-dc3269c56f06"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.zeros_like(input=one_to_ten)` creates a new tensor filled with zeros that has the **same shape, data type, and device** as the tensor `one_to_ten`.\n",
        "\n",
        "`ten_Zeros` stores this new zero tensor, so it can be used later for computations while preserving the structure of `one_to_ten`.\n"
      ],
      "metadata": {
        "id": "IXr6EhCXEJo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Tensor Data Types (dtypes)\n",
        "\n",
        "A tensor’s **data type (dtype)** defines what kind of values the tensor can store and how much memory each value uses.\n",
        "\n",
        "### 1. Integer Types\n",
        "\n",
        "Used for whole numbers (no decimals).\n",
        "\n",
        "* `torch.int8` — 8-bit signed integer\n",
        "* `torch.uint8` — 8-bit unsigned integer\n",
        "* `torch.int16` — 16-bit signed integer\n",
        "* `torch.int32` — 32-bit signed integer\n",
        "* `torch.int64` — 64-bit signed integer (default for integer tensors)\n",
        "\n",
        "These are typically used for indexing, counts, or discrete values.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Floating-Point Types\n",
        "\n",
        "Used for real numbers (with decimals).\n",
        "\n",
        "* `torch.float16` — half precision\n",
        "* `torch.float32` — single precision (default for float tensors)\n",
        "* `torch.float64` — double precision\n",
        "\n",
        "Floating-point tensors are mainly used for neural networks, scientific computing, and optimization.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Boolean Type\n",
        "\n",
        "Used for logical values.\n",
        "\n",
        "* `torch.bool` — stores `True` or `False`\n",
        "\n",
        "Commonly used for masks and condition filtering.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Complex Types\n",
        "\n",
        "Used for complex numbers.\n",
        "\n",
        "* `torch.complex64` — complex with 32-bit real and imaginary parts\n",
        "* `torch.complex128` — complex with 64-bit real and imaginary parts\n",
        "\n",
        "Used in signal processing, physics, and advanced mathematics.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Table\n",
        "\n",
        "| Category | Data Type                         | Use Case                     |\n",
        "| -------- | --------------------------------- | ---------------------------- |\n",
        "| Integers | `int8`, `int16`, `int32`, `int64` | Counting, indexing           |\n",
        "| Floats   | `float16`, `float32`, `float64`   | ML models, continuous values |\n",
        "| Boolean  | `bool`                            | Masks, conditions            |\n",
        "| Complex  | `complex64`, `complex128`         | Signal processing, physics   |\n",
        "\n",
        "---\n",
        "\n",
        "## Important Notes\n",
        "\n",
        "* The default integer dtype is `torch.int64`.\n",
        "* The default floating dtype is `torch.float32`.\n",
        "* Choosing the right dtype helps save memory and improve performance.\n",
        "* Lower precision (like `float16`) is faster but less accurate.\n"
      ],
      "metadata": {
        "id": "QrsFuoWQEfMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Integer type\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.int8)\n",
        "b = torch.tensor([1, 2, 3], dtype=torch.int16)\n",
        "c = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
        "d = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
        "\n",
        "print(a, a.dtype)\n",
        "print(b, b.dtype)\n",
        "print(c, c.dtype)\n",
        "print(d, d.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsLFbWoOFNnZ",
        "outputId": "3f459d29-0193-4e6f-c697-3a661e19bff5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], dtype=torch.int8) torch.int8\n",
            "tensor([1, 2, 3], dtype=torch.int16) torch.int16\n",
            "tensor([1, 2, 3], dtype=torch.int32) torch.int32\n",
            "tensor([1, 2, 3]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Float Type\n",
        "e = torch.tensor([1.5, 2.5, 3.5], dtype=torch.float16)\n",
        "f = torch.tensor([1.5, 2.5, 3.5], dtype=torch.float32)\n",
        "g = torch.tensor([1.5, 2.5, 3.5], dtype=torch.float64)\n",
        "\n",
        "print(e, e.dtype)\n",
        "print(f, f.dtype)\n",
        "print(g, g.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X1r1qN4Gcmy",
        "outputId": "35cac03b-0ed6-4fd4-f42b-e4909a28e7c1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.5000, 2.5000, 3.5000], dtype=torch.float16) torch.float16\n",
            "tensor([1.5000, 2.5000, 3.5000]) torch.float32\n",
            "tensor([1.5000, 2.5000, 3.5000], dtype=torch.float64) torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Boolean Type\n",
        "h = torch.tensor([True, False, True], dtype=torch.bool)\n",
        "print(h, h.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW0Lamr9GiRa",
        "outputId": "ac0b4960-7cd4-45fb-edeb-f695465f20bb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ True, False,  True]) torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complex Type\n",
        "i = torch.tensor([1+2j, 3+4j], dtype=torch.complex64)\n",
        "j = torch.tensor([1+2j, 3+4j], dtype=torch.complex128)\n",
        "\n",
        "print(i, i.dtype)\n",
        "print(j, j.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "377obMsnGnR6",
        "outputId": "4a906766-66dd-4923-d1c4-51fa6f8a1d76"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.+2.j, 3.+4.j]) torch.complex64\n",
            "tensor([1.+2.j, 3.+4.j], dtype=torch.complex128) torch.complex128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converstion Type\n",
        "x = torch.tensor([1, 2, 3])\n",
        "\n",
        "print(x.dtype)\n",
        "\n",
        "x_float = x.float()\n",
        "x_double = x.double()\n",
        "x_bool = x.bool()\n",
        "\n",
        "print(x_float.dtype)\n",
        "print(x_double.dtype)\n",
        "print(x_bool.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB8UkHvFGuJa",
        "outputId": "38a73a6a-967a-4cbb-9b67-1670236f0f88"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Let’s understand **what “8-bit, 16-bit, 32-bit, 64-bit” actually mean in tensor data types**.\n",
        "\n",
        "---\n",
        "\n",
        "### What does “bit” mean here?\n",
        "\n",
        "A **bit (binary digit)** is the smallest unit of memory.\n",
        "It can be either `0` or `1`.\n",
        "\n",
        "When we say:\n",
        "\n",
        "* `int8` → **8 bits per value**\n",
        "* `int16` → **16 bits per value**\n",
        "* `float32` → **32 bits per value**\n",
        "* `float64` → **64 bits per value**\n",
        "\n",
        "…it means **how many bits of memory are used to store one single number**.\n",
        "\n",
        "---\n",
        "\n",
        "## Why does this matter?\n",
        "\n",
        "Because the number of bits controls:\n",
        "\n",
        "1. **How large or precise a number can be**\n",
        "2. **How much memory the tensor uses**\n",
        "3. **How fast computations are**\n",
        "\n",
        "---\n",
        "\n",
        "## Bit size → range & precision\n",
        "\n",
        "### Integer types\n",
        "\n",
        "| Type  | Bits            | Range                    |\n",
        "| ----- | --------------- | ------------------------ |\n",
        "| int8  | 8 bits          | −128 to 127              |\n",
        "| uint8 | 8 bits unsigned | 0 to 255                 |\n",
        "| int16 | 16 bits         | −32,768 to 32,767        |\n",
        "| int32 | 32 bits         | −2 billion to +2 billion |\n",
        "| int64 | 64 bits         | very large range         |\n",
        "\n",
        "More bits → larger numbers possible.\n",
        "\n",
        "---\n",
        "\n",
        "### Floating-point types\n",
        "\n",
        "Floating numbers use bits for:\n",
        "\n",
        "* sign (positive/negative),\n",
        "* exponent (scale),\n",
        "* mantissa (precision).\n",
        "\n",
        "| Type    | Bits    | Approx Precision   |\n",
        "| ------- | ------- | ------------------ |\n",
        "| float16 | 16 bits | ~3 decimal digits  |\n",
        "| float32 | 32 bits | ~7 decimal digits  |\n",
        "| float64 | 64 bits | ~15 decimal digits |\n",
        "\n",
        "More bits → more accurate decimal representation.\n",
        "\n",
        "---\n",
        "\n",
        "## Memory example\n",
        "\n",
        "Suppose you have 1 million numbers:\n",
        "\n",
        "| Type    | Bits per value | Memory |\n",
        "| ------- | -------------- | ------ |\n",
        "| int8    | 8 bits         | ~1 MB  |\n",
        "| float32 | 32 bits        | ~4 MB  |\n",
        "| float64 | 64 bits        | ~8 MB  |\n",
        "\n",
        "So choosing the right dtype can save a lot of memory.\n",
        "\n",
        "---\n",
        "\n",
        "## Simple intuition\n",
        "\n",
        "Think of **bits like the number of boxes you have to store information**:\n",
        "\n",
        "* 8 boxes → you can store small things, fast, cheap.\n",
        "* 64 boxes → you can store very detailed, very big things, but slower and costly.\n",
        "\n",
        "---\n",
        "\n",
        "## One-line summary\n",
        "\n",
        "**The “bit” size tells you how much memory one tensor element uses, which directly controls the range, precision, speed, and memory usage of your tensor.**\n"
      ],
      "metadata": {
        "id": "eC43Pza2HahK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with dtype, device, and requires_grad\n",
        "x = torch.tensor([1.0, 2.0, 3.0],\n",
        "                 dtype=None,\n",
        "                 device= None,\n",
        "                 requires_grad=False)\n",
        "x.dtype, x.device, x.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHheJW9-Hj_6",
        "outputId": "4f557eb8-1e47-4743-c60b-d0612ecf1026"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, device(type='cpu'), False)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Device\n",
        "\n",
        "The device argument specifies where a tensor is stored and where computations on it will happen.\n",
        "Common values are \"cpu\" for the processor and \"cuda\" for the GPU.\n",
        "Using a GPU can significantly speed up large numerical computations, but GPU memory is limited.\n",
        "\n",
        "requires_grad\n",
        "\n",
        "The requires_grad argument tells PyTorch whether it should track operations on the tensor so that gradients can be computed later.\n",
        "It is mainly used during training of neural networks for backpropagation.\n",
        "If requires_grad=False, no gradient information is stored."
      ],
      "metadata": {
        "id": "ICQNWvVwJUqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1EBLZTavsHsY",
        "outputId": "3bfcba4b-3f2e-4e7a-bbfe-d6016904e737"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the mistake if any\n",
        "folat_16_tensor = torch.tensor([1.0, 2.0, 3.0]) # Re-initialize x as a tensor\n",
        "folat_32_tensor = folat_16_tensor.type(torch.float64) # Convert x to float64 (double precision)\n",
        "folat_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUZcRyQlK7CS",
        "outputId": "b8d600ac-05e6-414b-a6ba-b656ef5288eb"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Operation on diff data type"
      ],
      "metadata": {
        "id": "9Vu-IgfzFW-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Tensor A ↓ \\ Tensor B → | bool                     | int32                     | int64                     | float32                     | float64                     | complex64                         |\n",
        "| ----------------------- | ------------------------ | ------------------------- | ------------------------- | --------------------------- | --------------------------- | --------------------------------- |\n",
        "| **bool**                | bool × bool → bool       | bool → int32              | bool → int64              | bool → float32              | bool → float64              | not allowed                       |\n",
        "| **int32**               | int32 × bool → int32     | int32 × int32 → int32     | int32 → int64             | int32 → float32             | int32 → float64             | not allowed                       |\n",
        "| **int64**               | int64 × bool → int64     | int64 × int32 → int64     | int64 × int64 → int64     | int64 → float32             | int64 → float64             | not allowed                       |\n",
        "| **float32**             | float32 × bool → float32 | float32 × int32 → float32 | float32 × int64 → float32 | float32 × float32 → float32 | float32 → float64           | not allowed                       |\n",
        "| **float64**             | float64 × bool → float64 | float64 × int32 → float64 | float64 × int64 → float64 | float64 × float32 → float64 | float64 × float64 → float64 | not allowed                       |\n",
        "| **complex64**           | not allowed              | not allowed               | not allowed               | not allowed                 | not allowed                 | complex64 × complex64 → complex64 |\n"
      ],
      "metadata": {
        "id": "aOANpYnFFSXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.tensor([1], dtype=torch.int32) * torch.tensor([2.5], dtype=torch.float32)\n",
        "# result dtype: float32\n",
        "\n",
        "torch.tensor([True], dtype=torch.bool) * torch.tensor([10], dtype=torch.int64)\n",
        "# result dtype: int64\n",
        "\n",
        "torch.tensor([1.0], dtype=torch.float32) * torch.tensor([2.0], dtype=torch.float64)\n",
        "# result dtype: float64\n",
        "\n",
        "torch.tensor([1+2j], dtype=torch.complex64) * torch.tensor([3+4j], dtype=torch.complex64)\n",
        "# result dtype: complex64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM8NuR-yFje3",
        "outputId": "1b98b53b-ec56-430f-e19f-a529b38973c4"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5.+10.j])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor = torch.rand(3, 4)\n",
        "some_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQxOHr_qGCvG",
        "outputId": "ea4a6791-4deb-4847-ca92-5dfda52448d6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding out detials about some tensors\n",
        "print(some_tensor)\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5cn27v3Gma-",
        "outputId": "66fc22a7-5395-4013-f69a-d6fb46f6c514"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5779, 0.9040, 0.5547, 0.3423],\n",
            "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
            "        [0.7890, 0.2814, 0.7886, 0.5895]])\n",
            "Datatype of tensor: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor Operations in PyTorch\n",
        "\n",
        "Tensor operations are computations performed on tensors to transform, combine, or analyze data.\n",
        "\n",
        "They can be grouped into:\n",
        "\n",
        "1. Arithmetic operations\n",
        "\n",
        "2. Comparison operations\n",
        "\n",
        "3. Reduction operations\n",
        "\n",
        "4. Matrix operations\n",
        "\n",
        "5. Broadcasting operations\n",
        "\n",
        "In-place operations"
      ],
      "metadata": {
        "id": "DNPqSFDjKGWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Arithmetic Operations\n",
        "\n",
        "Performed element-wise unless stated otherwise."
      ],
      "metadata": {
        "id": "sSTvP27FJXa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1., 2., 3.])\n",
        "b = torch.tensor([4., 5., 6.])\n",
        "print(f'Adding two tensors {a + b}, Adding tensors by scalar{a + 10}')\n",
        "print(f'Subrating  two tensors {a - b}, Subrating tensors by scalar{a - 10}')\n",
        "print(f'Multiplying two tensors {a * b},Mutiplying  tensors by scalar{a * 10}')\n",
        "print(f'Dividing two tensors {a / b} , Dividing tensors by scalar{a / 10}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cVBvyYTHtnY",
        "outputId": "2ed83ecc-255e-4c9c-8767-312d58fe8c54"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding two tensors tensor([5., 7., 9.]), Adding tensors by scalartensor([11., 12., 13.])\n",
            "Subrating  two tensors tensor([-3., -3., -3.]), Subrating tensors by scalartensor([-9., -8., -7.])\n",
            "Multiplying two tensors tensor([ 4., 10., 18.]),Mutiplying  tensors by scalartensor([10., 20., 30.])\n",
            "Dividing two tensors tensor([0.2500, 0.4000, 0.5000]) , Dividing tensors by scalartensor([0.1000, 0.2000, 0.3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Comparison Operations\n",
        "\n",
        "Return boolean tensors."
      ],
      "metadata": {
        "id": "9VWUR7yoMQbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a > b)\n",
        "print(a == b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2ZsbM0YMRcF",
        "outputId": "7018ab40-4676-4ea4-8059-ecdb60424b9b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False, False, False])\n",
            "tensor([False, False, False])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Reduction Operations\n",
        "\n",
        "Reduce tensor to a smaller tensor or scalar."
      ],
      "metadata": {
        "id": "9QZU9yZhMKop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Operation | Code         | Result |\n",
        "| --------- | ------------ | ------ |\n",
        "| Sum       | `x.sum()`    | `10`   |\n",
        "| Mean      | `x.mean()`   | `2.5`  |\n",
        "| Max       | `x.max()`    | `4`    |\n",
        "| Argmax    | `x.argmax()` | `3`    |\n"
      ],
      "metadata": {
        "id": "iD4U3vuRMvMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1,2],[3,4]])\n",
        "print(x.sum())\n",
        "print(x.max())\n",
        "print(x.argmax())\n",
        "x = x.float()\n",
        "print(x.mean())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwRrkNvrMlaw",
        "outputId": "d3ab7d3f-ee0f-46d5-df88-5da41177eb5e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10)\n",
            "tensor(4)\n",
            "tensor(3)\n",
            "tensor(2.5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.rand(10)\n",
        "a , a.argmin(), a.argmax() , a.argwhere() , a.sort() , a.argsort()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50KcXX3JLY5u",
        "outputId": "8e6b155b-0887-4660-9511-fe7a2bdbe2b4"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103, 0.6440, 0.7071, 0.6581,\n",
              "         0.4913]),\n",
              " tensor(2),\n",
              " tensor(5),\n",
              " tensor([[0],\n",
              "         [1],\n",
              "         [2],\n",
              "         [3],\n",
              "         [4],\n",
              "         [5],\n",
              "         [6],\n",
              "         [7],\n",
              "         [8],\n",
              "         [9]]),\n",
              " torch.return_types.sort(\n",
              " values=tensor([0.0050, 0.1165, 0.1952, 0.3068, 0.4913, 0.6440, 0.6581, 0.7071, 0.7539,\n",
              "         0.9103]),\n",
              " indices=tensor([2, 4, 1, 3, 9, 6, 8, 7, 0, 5])),\n",
              " tensor([2, 4, 1, 3, 9, 6, 8, 7, 0, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Matrix Operations"
      ],
      "metadata": {
        "id": "XF-cWtlcNLu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Operation       | Code                           | Meaning        |\n",
        "| --------------- | ------------------------------ | -------------- |\n",
        "| Matrix multiply | `A @ B` or `torch.matmul(A,B)` | matrix product |\n",
        "| Transpose       | `A.T`                          | transpose      |\n"
      ],
      "metadata": {
        "id": "GAD5xdxBNLV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure:\n",
        "\n",
        "* Last dim of A == second-last dim of B\n",
        "\n",
        "* Batch dims are equal or broadcastable\n",
        "\n",
        "* No accidental 1D when you expect 2D"
      ],
      "metadata": {
        "id": "Yym475bhQljN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A = torch.randn(2,3)\n",
        "B = torch.randn(3,2)\n",
        "print(A @ B)\n",
        "print(torch.matmul(A,B))\n",
        "print(A.T)"
      ],
      "metadata": {
        "id": "Uvew6uYeEQYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373146ef-8a03-40ab-dbb6-3c210734a069"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5154, -0.4140],\n",
            "        [-4.2832,  0.3149]])\n",
            "tensor([[-0.5154, -0.4140],\n",
            "        [-4.2832,  0.3149]])\n",
            "tensor([[ 0.5200,  0.7113],\n",
            "        [ 0.5567, -0.5687],\n",
            "        [ 0.0744,  1.2580]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Broadcasting Operations\n",
        "\n",
        "Allows operations between different shapes."
      ],
      "metadata": {
        "id": "89-IAKAVChTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3,1)\n",
        "y = torch.ones(1,4)\n",
        "\n",
        "x + y  # result shape (3,4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqZR18WTNfwm",
        "outputId": "ed04c02b-ecbc-4f92-fed1-e1ec06d079e0"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting rules:\n",
        "\n",
        "Align dimensions from the right.\n",
        "\n",
        "Size must be equal or one of them must be 1."
      ],
      "metadata": {
        "id": "Ahx4tm4kNjUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. In-place Operations\n",
        "\n",
        "Modify tensor directly (end with _).\n",
        "\n",
        "Operation\tEffect\n",
        "add_\tin-place addition\n",
        "zero_\tfill with zeros\n",
        "\n",
        "⚠️ Be careful when using in-place ops with autograd."
      ],
      "metadata": {
        "id": "js9vQ4cRNnlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.add_(1))\n",
        "print(x.mul_(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOobLPrmNxXA",
        "outputId": "12e5db26-6391-4176-a64a-781d4cdddef6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.],\n",
            "        [2.],\n",
            "        [2.]])\n",
            "tensor([[4.],\n",
            "        [4.],\n",
            "        [4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A = torch.tensor([[1,2],\n",
        "                         [3,4],\n",
        "                         [5,6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7,10],\n",
        "                         [8,11],\n",
        "                         [9,12]])\n"
      ],
      "metadata": {
        "id": "j0gqpdL8N2WM"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix the issue of shape , we can use the manipulatin of the shape of one of the `Tensor` by using a `Transpose`\n",
        "A `Transpose` switches the dim opf thew tensor\n"
      ],
      "metadata": {
        "id": "Lj7bwhENU2dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gQDF0NyVn2p",
        "outputId": "e9fb1e4c-c6bb-48cc-c843-e38939bf4a1f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8,  9],\n",
              "        [10, 11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor_A = torch.tensor([[1,2],\n",
        "                         [3,4],\n",
        "                         [5,6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7,10],\n",
        "                         [8,11],\n",
        "                         [9,12]])\n",
        "Matmul = tensor_A @ tensor_B.T\n",
        "print(f' Matrixmultipication{Matmul}  ,and its shape is {Matmul.shape} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjDx18Qc6b0v",
        "outputId": "bd85fb70-32a8-4a35-ea17-e9f49c716ab1"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Matrixmultipicationtensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])  ,and its shape is torch.Size([3, 3]) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Operation | Definition                                |\n",
        "| --------- | ----------------------------------------- |\n",
        "| Reshape   | Change tensor shape without changing data |\n",
        "| Stack     | Join tensors by adding a new dimension    |\n",
        "| Cat       | Join tensors along an existing dimension  |\n",
        "| Squeeze   | Remove dimensions of size 1               |\n",
        "| Unsqueeze | Add a dimension of size 1                 |\n"
      ],
      "metadata": {
        "id": "1EGgAcEHUY4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Reshaping\n",
        "\n",
        "    Reshaping changes the shape of a tensor without changing its data."
      ],
      "metadata": {
        "id": "-INO4TQ-TtZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)        # shape: (6,)\n",
        "y = x.reshape(2, 3)        # shape: (2, 3)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIjGoMVJIf1l",
        "outputId": "6dd9f550-bc33-4cdd-bb0f-e8a5eb5e6b5e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Stacking\n",
        "\n",
        "    Stacking combines multiple tensors by adding a new dimension.\n",
        "\n"
      ],
      "metadata": {
        "id": "iC1qoxFGUGOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "\n",
        "s = torch.stack([a, b], dim=0)   # shape: (2, 3)\n",
        "print(s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByTwJGPcULT8",
        "outputId": "e9fb91e6-8045-4b4b-d369-aa527c4c63ec"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Concatenation (cat)\n",
        "Definition:\n",
        "\n",
        "Concatenation joins tensors along an existing dimension."
      ],
      "metadata": {
        "id": "4e9w_BZxU3aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.cat([a, b], dim=0)     # shape: (6,)\n",
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUGSHwvOU5VJ",
        "outputId": "50ff09df-7e03-4575-8649-0babf9ceedab"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Squeeze\n",
        "Definition:\n",
        "\n",
        "Squeeze removes all dimensions of size 1 from a tensor.\n",
        "\n",
        "Code:"
      ],
      "metadata": {
        "id": "yzrhBN2eU6H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 1, 5)\n",
        "y = x.squeeze()      # shape: (3, 5)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RglCZHclVCx9",
        "outputId": "ee0138f9-0d2f-4e3b-ae3e-0c332c7a3922"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 5. Unsqueeze\n",
        "Definition:\n",
        "\n",
        "Unsqueeze adds a new dimension of size 1 at the specified position."
      ],
      "metadata": {
        "id": "zwGtNqI7VH51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "y = x.unsqueeze(0)   # shape: (1, 3)\n",
        "print(y.shape)\n",
        "z = x.unsqueeze(1)   # shape: (3, 1)\n",
        "print(z.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fum1bXhfVKH4",
        "outputId": "9b77b8d9-38ff-491f-d8ae-84c39f0a1789"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Selecting Data (Indexing)\n",
        "\n",
        "Definition:\n",
        "\n",
        "`Indexing` allows you to extract, modify, or filter specific elements or sub-tensors from a tensor using positions, ranges, or conditions.\n",
        "\n",
        "Why it matters ?\n",
        "\n",
        "* Extract batches, features, or channels from data\n",
        "\n",
        "* Filter values based on conditions\n",
        "\n",
        "* Used heavily in preprocessing, loss functions, and evaluation"
      ],
      "metadata": {
        "id": "f7MzDSe0VdCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1,2,3],[4,5,6]])\n",
        "\n",
        "x[0, 1]      # element access → 2\n",
        "x[:, 1]      # column → tensor([2,5])\n",
        "x[0, :]      # row → tensor([1,2,3])\n",
        "x[0:2, 1:3]  # slicing\n",
        "x[x > 3]     # boolean mask\n"
      ],
      "metadata": {
        "id": "ldKQPQlr5rGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2173f4-237e-4664-af15-549483dcfda5"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.tensor([0, 2])\n",
        "torch.index_select(x, dim=1, index=idx)\n"
      ],
      "metadata": {
        "id": "ug3Ahnwb5t5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854b7409-deca-4e29-c3f4-3c44db180786"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3],\n",
              "        [4, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PyTorch ↔ NumPy Interoperability\n",
        "\n",
        "Definition:\n",
        "\n",
        "`PyTorch` and `NumPy` can share memory, allowing zero-copy conversion between tensors and arrays on CPU."
      ],
      "metadata": {
        "id": "tR9tPMmo5vCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create NumPy data\n",
        "np_data = np.linspace(0, 10, 100)\n",
        "\n",
        "# Step 2: Convert to PyTorch tensor\n",
        "torch_data = torch.from_numpy(np_data).float()\n",
        "\n",
        "# Step 3: Simple transformation in PyTorch\n",
        "torch_data = torch_data * 2\n",
        "\n",
        "# Step 4: Convert back to NumPy for plotting\n",
        "np_out = torch_data.numpy()\n",
        "\n",
        "plt.plot(np_out)\n",
        "plt.title(\"Processed Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "HeryIctk5vAA",
        "outputId": "b4f36e12-3a3a-4dbd-b827-2c43fcd7ee30"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important Details\n",
        "\n",
        "* .numpy() works only on CPU tensors\n",
        "\n",
        "* Shared memory → modifying one affects the other\n",
        "\n",
        "* NumPy defaults to `float64`, PyTorch defaults to `float32`"
      ],
      "metadata": {
        "id": "L25eGLM05u9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reproducibility\n",
        "\n",
        "Definition:\n",
        "\n",
        "Reproducibility ensures that model training and experiments produce consistent results across runs.\n",
        "\n",
        "Why needed ?\n",
        "\n",
        "* Debugging\n",
        "\n",
        "* Comparing models fairly\n",
        "\n",
        "* Research reproducibility\n",
        "\n",
        "* Seed setup"
      ],
      "metadata": {
        "id": "Q50sbKrw5u6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = torch.nn.Linear(1, 1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "x = torch.randn(10, 1)\n",
        "y = 3*x + 2\n",
        "\n",
        "for _ in range(5):\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(x)\n",
        "    loss = ((pred - y)**2).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(model.weight, model.bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkVmzgUL7MVe",
        "outputId": "74cfd8af-3127-4800-da28-fe4abdb059fc"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[2.1707]], requires_grad=True) Parameter containing:\n",
            "tensor([1.7263], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "Random_tensor_A = torch.rand(3 , 2)\n",
        "Random_tensor_A\n",
        "\n",
        "Random_tensor_B = torch.rand(3 , 2)\n",
        "\n",
        "Random_tensor_A ,  Random_tensor_B , Random_tensor_A == Random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoGlMOKWmVRO",
        "outputId": "55531766-9d22-4793-9265-ee853c0096f0"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.2969, 0.8317],\n",
              "         [0.1053, 0.2695],\n",
              "         [0.3588, 0.1994]]),\n",
              " tensor([[0.5472, 0.0062],\n",
              "         [0.9516, 0.0753],\n",
              "         [0.8860, 0.5832]]),\n",
              " tensor([[False, False],\n",
              "         [False, False],\n",
              "         [False, False]]))"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Random tensor But  with some Reproduceblity\n",
        "import torch\n",
        "\n",
        "#Set a random SEED\n",
        "\n",
        "torch.manual_seed(42)\n",
        "Random_tensor_A = torch.rand(3 , 2)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "Random_tensor_B = torch.rand(3 , 2)\n",
        "\n",
        "Random_tensor_A ,  Random_tensor_B , Random_tensor_A == Random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzwwvsMDomkC",
        "outputId": "c5c6be8a-3724-4b0d-9c9e-296d646bc5e6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8823, 0.9150],\n",
              "         [0.3829, 0.9593],\n",
              "         [0.3904, 0.6009]]),\n",
              " tensor([[0.8823, 0.9150],\n",
              "         [0.3829, 0.9593],\n",
              "         [0.3904, 0.6009]]),\n",
              " tensor([[True, True],\n",
              "         [True, True],\n",
              "         [True, True]]))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Source          | What it controls              |\n",
        "| --------------- | ----------------------------- |\n",
        "| Python `random` | Sampling, shuffling           |\n",
        "| NumPy RNG       | Data generation               |\n",
        "| PyTorch RNG     | Weight init, dropout, shuffle |\n",
        "| CUDA RNG        | GPU randomness                |\n"
      ],
      "metadata": {
        "id": "ZZhOQXkR67sP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Device"
      ],
      "metadata": {
        "id": "OGhpK0iRws7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count the No. of GPU\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZs3KrMwpZ2q",
        "outputId": "d3b7afef-a130-4560-bb79-b0b81e113cd6"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "\n",
        "Tensor_a = torch.tensor([1,2,3])\n",
        "Tensor_a , Tensor_a.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db-sZ43bsnfF",
        "outputId": "7a0c7180-d0f6-45bf-b1e1-3a0c496ee87a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor_on_GPU = Tensor_a.to(device)\n",
        "Tensor_on_GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH4eZFRetiqK",
        "outputId": "512ff9e5-eb58-4852-ab09-0edfc8d5ed73"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving back to cpu\n",
        "# when we tnasfor to Numpy it only works on the CPU so you have to transfor the tenors from gpu tp cpu\n",
        "tensor_back_on_cpu = Tensor_on_GPU.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diSKN_O5timA",
        "outputId": "b67b1977-6d12-4b71-b786-a48b659cb7ce"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    }
  ]
}